### Week 1

These are notes of the first week of Inferential Statistics.  I'm utting them in a markdown document and loading up to GitHub as an experient in workflow.

Let the fun begin.

- Samply Variability - estimates how one sample varies from another
- Samplying Distribution
    + Take sample statistics, e.g. mean, mode, etc., from several different samples from the population and then look at them as a group... finding the **SampLING Distribution**. 
    + Standard Deviation of the Sample Means (SampLING Distribution) is called the **Standard Error$**.  **sd of x(bar) = (SE)**
    + As n increses the Standard Error will decrease.

While individial populations are "very variable", it is unlikey that sample means will be "very variable".  The histogram of the sampLING distribtion is a lot skinnier than the population histogram.

The higher the sample size that we take from the population, the less variable the means of the samples, e.g. they get tall and very skinny.

**The Central Limit Theory** says that The distribution of the sample statistic is nearly normal (bell shaped), centered at the population mean, with a standard deviation equal to the population standard deviation divided by the sqr root of the sample size.

**CLT** requirements:
- Independence

- if sampling **without replacement** the sample size (n) < 10% of the population.  *The reason is that within large samples there is often less independence, a family getting sampled in a town of 1000 pop*

- If population is not normal, e.g., skewed we need a larger sample size, generally > 30.  The larger the sample size the closer to normal the sampLINGdistribution becomes.  Normal samples lend themselves to probability calculations.  **"The more the skew the mores sample size you need for the CLT to kick-in"**.



